{"posts":[{"title":"clickhouse installation on centos 7.8","content":"系统检查 # grep -q sse4_2 /proc/cpuinfo &amp;&amp; echo &quot;SSE 4.2 supported&quot; || echo &quot;SSE 4.2 not supported&quot; SSE 4.2 supported RPM包安装 建议对CentOS，RedHat和所有其他基于rpm的Linux发行版使用官方的预编译rpm软件包。 sudo yum install yum-utils sudo rpm --import https://repo.clickhouse.tech/CLICKHOUSE-KEY.GPG sudo yum-config-manager --add-repo https://repo.clickhouse.tech/rpm/stable/x86_64 启动 systemctl daemon-reload systemctl start clickhouse-server.service # systemctl status clickhouse-server.service ● clickhouse-server.service - ClickHouse Server (analytic DBMS for big data) Loaded: loaded (/etc/systemd/system/clickhouse-server.service; enabled; vendor preset: disabled) Active: active (running) since Tue 2020-06-02 15:45:22 CST; 8s ago Main PID: 13949 (clickhouse-serv) Tasks: 44 Memory: 163.9M CGroup: /system.slice/clickhouse-server.service └─13949 /usr/bin/clickhouse-server --config=/etc/clickhouse-server/config.xml --pid-file=/run/clickhouse-server/clickhouse-server.pid Jun 02 15:45:22 hqcentos clickhouse-server[13949]: Include not found: clickhouse_compression Jun 02 15:45:22 hqcentos clickhouse-server[13949]: Logging trace to /var/log/clickhouse-server/clickhouse-server.log Jun 02 15:45:22 hqcentos clickhouse-server[13949]: Logging errors to /var/log/clickhouse-server/clickhouse-server.err.log Jun 02 15:45:28 hqcentos clickhouse-server[13949]: Processing configuration file '/etc/clickhouse-server/users.xml'. Jun 02 15:45:28 hqcentos clickhouse-server[13949]: Include not found: networks Jun 02 15:45:28 hqcentos clickhouse-server[13949]: Saved preprocessed configuration to '/var/lib/clickhouse//preprocessed_configs/users.xml'. Jun 02 15:45:30 hqcentos clickhouse-server[13949]: Processing configuration file '/etc/clickhouse-server/config.xml'. Jun 02 15:45:30 hqcentos clickhouse-server[13949]: Include not found: clickhouse_remote_servers Jun 02 15:45:30 hqcentos clickhouse-server[13949]: Include not found: clickhouse_compression Jun 02 15:45:30 hqcentos clickhouse-server[13949]: Saved preprocessed configuration to '/var/lib/clickhouse//preprocessed_configs/config.xml'. 登录 # clickhouse-client ClickHouse client version 20.4.4.18 (official build). Connecting to localhost:9000 as user default. Connected to ClickHouse server version 20.4.4 revision 54434. hqcentos :) select 1; SELECT 1 ┌─1─┐ │ 1 │ └───┘ 1 rows in set. Elapsed: 0.002 sec. hqcentos :) 简单的安装配置到此结束 ","link":"https://hkxtor.github.io/t-ZQVW9TS/"},{"title":"Oracle rman恢复遇到Error validating file dummy (36) in piece xxx: missing header","content":"过程 用参数拉起实例后，还原控制文件，数据库拉起到mount状态，catalog start with xx注册备份文件。 现象 执行catalog start with xx后，alert日志出现以下信息 Thu May 14 11:18:24 2020 Setting recovery target incarnation to 2 Setting recovery target incarnation to 2 Error validating file dummy (14) in piece xxx: missing header Expanded controlfile section 14 from 245 to 490 records Requested to grow by 245 recards; added 3 blocks of records 执行还原脚本出现以下报错后退出 ORA-01180: can not create datafile 1 ORA-01110: data file 1: '+DATA/xxxx/datafile/system01.dbf' 解决过程 rman中查看incarnation RMAN&gt; list incarnation; List of Database Incarnations DB Key Inc Key DB Name DB ID STATUS Reset SCN Reset Time ------- ------- -------- ---------------- ------ ------------------ ---------- 1 1 ORCL 1446008355 PARENT 1 2014/12/26 14:31:00 2 2 ORCL 1446008355 CURRENT 17034938503292 2020/05/09 17:34:36 重置incarnation回1 RMAN&gt; reset database to incarnation 1; database reset to incatnation 1 RMAN&gt; list incarnation; List of Database Incarnations DB Key Inc Key DB Name DB ID STATUS Reset SCN Reset Time ------- ------- -------- ---------------- ------ ------------------ ---------- 1 1 ORCL 1446008355 CURRENT 1 2014/12/26 14:31:00 2 2 ORCL 1446008355 ORPHAN 17034938503292 2020/05/09 17:34:36 观察alert日志 Thu May 14 11:21:28 2020 Setting recovery target incarnation to 1 在执行还原脚本，还原成功 ","link":"https://hkxtor.github.io/DAs8G2vZY/"},{"title":"mysql无损/半同步复制","content":"1.参数文件里加 plugin_dir=/usr/local/mysql/lib/plugin plugin_load = &quot;rpl_semi_sync_master=semisync_master.so;rpl_semi_sync_slave=semisync_slave.so&quot; loose_rpl_semi_sync_master_enabled = 1 loose_rpl_semi_sync_slave_enabled = 1 loose_rpl_semi_sync_master_timeout = 5000 2.主库准备步骤 grant replication slave, replication client on *.* to rep@'192.168.56.%' identified by '123456'; flush privileges; mysql&gt; show master status; +------------+----------+--------------+------------------+----------------------------------------------+ | File | Position | Binlog_Do_DB | Binlog_Ignore_DB | Executed_Gtid_Set | +------------+----------+--------------+------------------+----------------------------------------------+ | bin.000007 | 57566891 | | | 35d3ad22-8862-11ea-97a1-080027bb5279:1-43998 | +------------+----------+--------------+------------------+----------------------------------------------+ 3.备库准备步骤 change master to master_host='192.168.56.101',master_user='rep',master_password='123456',master_log_file='bin.000007', master_log_pos=57566891,master_port = 3306; 4.测试 # 主库执行 mysql&gt; show variables like '%rpl%'; +-------------------------------------------+------------+ | Variable_name | Value | +-------------------------------------------+------------+ | rpl_semi_sync_master_enabled | ON | | rpl_semi_sync_master_timeout | 5000 | | rpl_semi_sync_master_trace_level | 32 | | rpl_semi_sync_master_wait_for_slave_count | 1 | | rpl_semi_sync_master_wait_no_slave | ON | | rpl_semi_sync_master_wait_point | AFTER_SYNC | | rpl_semi_sync_slave_enabled | ON | | rpl_semi_sync_slave_trace_level | 32 | | rpl_stop_slave_timeout | 31536000 | +-------------------------------------------+------------+ 9 rows in set (0.00 sec) mysql&gt; show global status like &quot;%rpl%&quot;; +--------------------------------------------+-------+ | Variable_name | Value | +--------------------------------------------+-------+ | Rpl_semi_sync_master_clients | 1 | | Rpl_semi_sync_master_net_avg_wait_time | 0 | | Rpl_semi_sync_master_net_wait_time | 0 | | Rpl_semi_sync_master_net_waits | 0 | | Rpl_semi_sync_master_no_times | 1 | | Rpl_semi_sync_master_no_tx | 2 | | Rpl_semi_sync_master_status | ON | | Rpl_semi_sync_master_timefunc_failures | 0 | | Rpl_semi_sync_master_tx_avg_wait_time | 0 | | Rpl_semi_sync_master_tx_wait_time | 0 | | Rpl_semi_sync_master_tx_waits | 0 | | Rpl_semi_sync_master_wait_pos_backtraverse | 0 | | Rpl_semi_sync_master_wait_sessions | 0 | | Rpl_semi_sync_master_yes_tx | 0 | | Rpl_semi_sync_slave_status | OFF | +--------------------------------------------+-------+ 15 rows in set (0.00 sec) # 从库执行 mysql&gt; show global variables like '%semi%'; +-------------------------------------------+------------+ | Variable_name | Value | +-------------------------------------------+------------+ | rpl_semi_sync_master_enabled | ON | | rpl_semi_sync_master_timeout | 5000 | | rpl_semi_sync_master_trace_level | 32 | | rpl_semi_sync_master_wait_for_slave_count | 1 | | rpl_semi_sync_master_wait_no_slave | ON | | rpl_semi_sync_master_wait_point | AFTER_SYNC | | rpl_semi_sync_slave_enabled | ON | | rpl_semi_sync_slave_trace_level | 32 | +-------------------------------------------+------------+ 8 rows in set (0.00 sec) mysql&gt; stop slave io_thread; Query OK, 0 rows affected (0.00 sec) # 主库执行 mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | +--------------------+ 4 rows in set (0.00 sec) mysql&gt; create database test; Query OK, 1 row affected (5.00 sec) ---(rpl_semi_sync_master_timeout设置的5秒超时) mysql&gt; show global status like &quot;%rpl%&quot;; +--------------------------------------------+-------+ | Variable_name | Value | +--------------------------------------------+-------+ | Rpl_semi_sync_master_clients | 0 | | Rpl_semi_sync_master_net_avg_wait_time | 0 | | Rpl_semi_sync_master_net_wait_time | 0 | | Rpl_semi_sync_master_net_waits | 0 | | Rpl_semi_sync_master_no_times | 2 | | Rpl_semi_sync_master_no_tx | 3 | | Rpl_semi_sync_master_status | OFF | | Rpl_semi_sync_master_timefunc_failures | 0 | | Rpl_semi_sync_master_tx_avg_wait_time | 0 | | Rpl_semi_sync_master_tx_wait_time | 0 | | Rpl_semi_sync_master_tx_waits | 0 | | Rpl_semi_sync_master_wait_pos_backtraverse | 0 | | Rpl_semi_sync_master_wait_sessions | 0 | | Rpl_semi_sync_master_yes_tx | 0 | | Rpl_semi_sync_slave_status | OFF | +--------------------------------------------+-------+ 15 rows in set (0.00 sec) # 从库执行 start slave io_thread; # 主库执行 mysql&gt; show global status like &quot;%rpl%&quot;; +--------------------------------------------+-------+ | Variable_name | Value | +--------------------------------------------+-------+ | Rpl_semi_sync_master_clients | 1 | | Rpl_semi_sync_master_net_avg_wait_time | 0 | | Rpl_semi_sync_master_net_wait_time | 0 | | Rpl_semi_sync_master_net_waits | 1 | | Rpl_semi_sync_master_no_times | 2 | | Rpl_semi_sync_master_no_tx | 3 | | Rpl_semi_sync_master_status | ON | | Rpl_semi_sync_master_timefunc_failures | 0 | | Rpl_semi_sync_master_tx_avg_wait_time | 0 | | Rpl_semi_sync_master_tx_wait_time | 0 | | Rpl_semi_sync_master_tx_waits | 0 | | Rpl_semi_sync_master_wait_pos_backtraverse | 0 | | Rpl_semi_sync_master_wait_sessions | 0 | | Rpl_semi_sync_master_yes_tx | 0 | | Rpl_semi_sync_slave_status | OFF | +--------------------------------------------+-------+ 15 rows in set (0.00 sec) ","link":"https://hkxtor.github.io/BwozcZWlU/"},{"title":"MySQL自带的性能压力测试工具mysqlslap","content":"--only-print 只打印测试语句而不实际执行。 --detach=N 执行N条语句后断开重连。 # 单线程测试。测试做了什么。 mysqlslap -a -uroot -p123456 # 多线程测试。使用–concurrency来模拟并发连接。 mysqlslap -a -c 100 -uroot -p123456 # 迭代测试。用于需要多次执行测试得到平均值。 mysqlslap -a -i 10 -uroot -p123456 mysqlslap --auto-generate-sql-add-autoincrement -a -uroot -p123456 mysqlslap -a --auto-generate-sql-load-type=mixed -uroot -p123456 mysqlslap -a --auto-generate-sql-secondary-indexes=3 -uroot -p123456 mysqlslap -a --auto-generate-sql-write-number=1000 -uroot -p123456 mysqlslap --create-schema world -q &quot;select count(*) from City&quot; -uroot -p123456 mysqlslap -a -e innodb -uroot -p123456 mysqlslap -a --number-of-queries=10 -uroot -p123456 # 测试同时不同的存储引擎的性能进行对比： mysqlslap -a --concurrency=50,100 --number-of-queries 1000 --iterations=5 --engine=myisam,innodb --debug-info -uroot -p123456 # 500和1000个并发分别得到一次测试结果(Benchmark)，并发数越多，执行完所有查询的时间越长。为了准确起见，可以多测试几次: mysqlslap -a --concurrency=500,1000 --auto-generate-sql-add-autoincrement --auto-generate-sql-secondary-indexes=10 --number-of-queries 2000 --iterations=5 Benchmark Average number of seconds to run all queries: 1.551 seconds Minimum number of seconds to run all queries: 1.441 seconds Maximum number of seconds to run all queries: 1.716 seconds Number of clients running queries: 500 Average number of queries per client: 4 Benchmark Average number of seconds to run all queries: 1.734 seconds Minimum number of seconds to run all queries: 1.589 seconds Maximum number of seconds to run all queries: 1.911 seconds Number of clients running queries: 1000 Average number of queries per client: 2 ","link":"https://hkxtor.github.io/DQakzE_dy/"},{"title":"MySQL体系结构与管理","content":"1.体系结构 1.1 C/S模型 TCP/IP方式（远程、本地）： mysql -uroot -123456 -h 10.0.0.51 -P3306 Socket方式(仅本地)： mysql -uroot -123456 -S /tmp/mysql.sock 1.2 实例 实例=mysqld后台守护进程+Master Thread +干活的Thread+预分配的内存 1.3 mysqld 1.3.1 mysqld程序结构 1.3.1.1 连接层 1.3.2.1 连接层 （1）提供连接协议：TCP/IP 、SOCKET （2）提供验证：用户、密码，IP，SOCKET （3）提供专用连接线程：接收用户SQL，返回结果 通过以下语句可以查看到连接线程基本情况 mysql&gt; show processlist; 1.3.1.2 SQL层 （1）接收上层传送的SQL语句 （2）语法验证模块：验证语句语法,是否满足SQL_MODE （3）语义检查：判断SQL语句的类型 DDL ：数据定义语言 DCL ：数据控制语言 DML ：数据操作语言 DQL： 数据查询语言 （4）权限检查：用户对库表有没有权限 （5）解析器：对语句执行前,进行预处理，生成解析树(执行计划),说白了就是生成多种执行方案. （6）优化器：根据解析器得出的多种执行计划，进行判断，选择最优的执行计划代价模型：资源（CPU IO MEM）的耗损评估性能好坏 （7）执行器：根据最优执行计划，执行SQL语句，产生执行结果执行结果：在磁盘的xxxx位置上 （8）提供查询缓存（默认是没开启的），会使用redis tair替代查询缓存功能 （9）提供日志记录（日志管理章节）：binlog，默认是没开启的。 1.3.1.3 存储引擎层 负责根据SQL层执行的结果，从磁盘上拿数据。 将16进制的磁盘数据，交由SQL结构化化成表，由连接层的专用线程返回给用户。 1.4 逻辑结构 1.4.1 库 每一个库都有库名、库属性组成，库属性包括字符集、校对规则等等。 1.4.2 表（二维表） 每一张表都有表名、属性、列（列名）、列属性（数据类型、约束等等）、数据行（record）、元数据组成。 1.5 物理结构 1.5.1 库的物理存储结构 每一个库的物理存储结构都是由文件系统的目录来存储的，一个库就是一个目录。 mysql&gt; show databases; +--------------------+ | Database | +--------------------+ | information_schema | | mysql | | performance_schema | | sys | | test | +--------------------+ 5 rows in set (0.00 sec) [root@mysql1 data]# ls -ltr drwxr-x---. 2 mysql mysql 8192 Apr 27 16:36 performance_schema drwxr-x---. 2 mysql mysql 4096 Apr 27 16:36 mysql drwxr-x---. 2 mysql mysql 8192 Apr 27 16:36 sys drwxr-x---. 2 mysql mysql 20 Apr 28 16:57 test 1.5.2 表的物理存储结构 MyISAM（一种引擎）的表： -rw-r----- 1 mysql mysql 10816 Apr 18 11:37 user.frm -rw-r----- 1 mysql mysql 396 Apr 18 12:20 user.MYD -rw-r----- 1 mysql mysql 4096 Apr 18 14:48 user.MYI InnoDB(默认的存储引擎)的表： -rw-r----- 1 mysql mysql 8636 Apr 18 11:37 time_zone.frm -rw-r----- 1 mysql mysql 98304 Apr 18 11:37 time_zone.ibd time_zone.frm：存储列相关信息 time_zone.ibd：数据行+索引 1.5.3 表的段、区、页 页：最小的存储单元，默认16k 区：64个连续的页，共1M 段：一个表就是一个段，包含一个或多个区 2. 基础管理 2.1 用户、权限管理 2.1.1 用户 作用： 登录，管理数据库逻辑对象 定义： 用户名@'白名单' 白名单支持的方式： root@'%' 允许所有地址、域名 root@'192.0.0.%' 允许192.0.0.0/24 root@'192..0.0.200' 只允许这个用记在200地址的这台机器上登录 root@'localhost' 只能本地连接 root@'db01' 只能这个域名 root@'192.0.0.5%' 只能50-59ip的用户登录 root@'192.0.0.0/255.255.254.0' 只允许这个网段的子网掩码是254的用户登录 管理： 增： mysql&gt; create user hkxtor@'10.0.0.%' identified by '123'; 查： mysql&gt; desc mysql.user; ----&gt; authentication_string mysql&gt; select user ,host ,authentication_string from mysql.user 改: mysql&gt; alter user hkxtor@'10.0.0.%' identified by '456'; 删： mysql&gt; drop user hkxtor@'10.0.0.%'; 2.1.2 权限 权限介绍： 相对于用户而言，用户所能访问只是权限的一部分功能，MySQL能精确针对用户修改用户对哪一个库或者哪一张表进行查询、修改、删除、创建权限，超级管理员还具备给别的用户进行用户授权的权限。 常用权限： ALL: SELECT,INSERT, UPDATE, DELETE, CREATE, DROP, RELOAD, SHUTDOWN, PROCESS, FILE, REFERENCES, INDEX, ALTER, SHOW DATABASES, SUPER, CREATE TEMPORARY TABLES, LOCK TABLES, EXECUTE, REPLICATION SLAVE, REPLICATION CLIENT, CREATE VIEW, SHOW VIEW, CREATE ROUTINE, ALTER ROUTINE, CREATE USER, EVENT, TRIGGER, CREATE TABLESPACE ALL : 以上所有权限，一般是普通管理员拥有的 with grant option：超级管理员才具备的，给别的用户授权的功能 演示： create user hkxtor@'%' identified by '123'; 创建用户以及设置访问区域及密码 grant all on test.* to hkxtor@'%'; 赋予用户hkxtor所有区域进行访问库test的权限 show grants for hkxtor@'%'; 查看用户所被赋予的权限 mysql [(none)]&gt;show grants for hkxtor@'%'; +--------------------------------------------------+ | Grants for hkxtor@% | +--------------------------------------------------+ | GRANT USAGE ON *.* TO 'hkxtor'@'%' | | GRANT ALL PRIVILEGES ON `test`.* TO 'hkxtor'@'%' | +--------------------------------------------------+ 2 rows in set (0.01 sec) revoke delete on test.* from 'hkxtor'@'%'; 删除用户的delete权限 管理员忘记密码： [root@mysql1 ~]# mysqld_safe --skip-grant-tables --skip-networking &amp; 关闭用户密码的验证 关闭tcp/ip的远程连接 mysql&gt; flush privileges; mysql&gt; alter user root@'localhost' identified by '123456'; [root@mysql1 ~]# pkill mysqld 2.2 连接管理 2.2.1 自带客户端 [root@mysql1 ~]# mysql -uroot -p -h localhost -P3306 Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 8 Server version: 5.7.29-log MySQL Community Server (GPL) Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql&gt; select @@socket; +-----------------+ | @@socket | +-----------------+ | /tmp/mysql.sock | +-----------------+ 1 row in set (0.00 sec) mysql&gt; ^DBye [root@mysql1 ~]# [root@mysql1 ~]# mysql -uroot -p -S /tmp/mysql.sock Enter password: Welcome to the MySQL monitor. Commands end with ; or \\g. Your MySQL connection id is 9 Server version: 5.7.29-log MySQL Community Server (GPL) Copyright (c) 2000, 2020, Oracle and/or its affiliates. All rights reserved. Oracle is a registered trademark of Oracle Corporation and/or its affiliates. Other names may be trademarks of their respective owners. Type 'help;' or '\\h' for help. Type '\\c' to clear the current input statement. mysql&gt; exit Bye [root@mysql1 ~]# mysql -uroot -p -e &quot;select user,host from mysql.user;&quot; Enter password: +---------------+--------------+ | user | host | +---------------+--------------+ | hkxtor | % | | rep | 192.168.56.% | | mysql.session | localhost | | mysql.sys | localhost | | root | localhost | +---------------+--------------+ [root@mysql1 ~]# mysql -uroot -p &lt; all.sql #导入备份文件 Enter password: 2.4 初始化配置 2.4.1 作用 控制MySQL的启动，影响到客户端的连接，也就是直接在linux命令行操作的时候进行参数的添加 2.4.2 初始化的方法 预编译 **配置文件(所有启动方式)** 命令行参数 (仅限于 mysqld_safe mysqld) 2.4.3 配置文件 默认路径： [root@db01 ~]# mysqld --help --verbose |grep my.cnf /etc/my.cnf /etc/mysql/my.cnf /usr/local/mysql/etc/my.cnf ~/.my.cnf 注: 默认情况下，MySQL启动时，会依次读取以上配置文件，如果有重复选项，会以最后一个文件设置的为准。 但是，如果启动时加入了--defaults-file=xxxx时，以上的所有文件都不会读取. 配置文件格式： [标签] 配置项=xxxx 标签类型：服务端、客户端 服务器端标签： [mysqld] [mysqld_safe] [server] 客户端标签： [mysql] [mysqldump] [client] 配置文件的示例展示： [root@db01 ~]# cat /etc/my.cnf [mysqld] user=mysql basedir=/app/mysql datadir=/data/mysql socket=/tmp/mysql.sock server_id=6 port=3306 log_error=/data/mysql/mysql.log [mysql] socket=/tmp/mysql.sock prompt=Master [\\\\d]&gt; 2.5 多实例 2.5.1 准备数据目录 mkdir -p /data/330{7,8,9}/data 2.5.2 准备配置文件 cat &gt; /data/3307/my.cnf &lt;&lt;EOF [mysqld] basedir=/app/mysql datadir=/data/3307/data socket=/data/3307/mysql.sock log_error=/data/3307/mysql.log port=3307 server_id=7 log_bin=/data/3307/mysql-bin EOF cat &gt; /data/3308/my.cnf &lt;&lt;EOF [mysqld] basedir=/app/mysql datadir=/data/3308/data socket=/data/3308/mysql.sock log_error=/data/3308/mysql.log port=3308 server_id=8 log_bin=/data/3308/mysql-bin EOF cat &gt; /data/3309/my.cnf &lt;&lt;EOF [mysqld] basedir=/app/mysql datadir=/data/3309/data socket=/data/3309/mysql.sock log_error=/data/3309/mysql.log port=3309 server_id=9 log_bin=/data/3309/mysql-bin EOF 2.5.3 分别初始化 mv /etc/my.cnf /etc/my.cnf.bak mysqld --initialize-insecure --user=mysql --datadir=/data/3307/data --basedir=/app/mysql mysqld --initialize-insecure --user=mysql --datadir=/data/3308/data --basedir=/app/mysql mysqld --initialize-insecure --user=mysql --datadir=/data/3309/data --basedir=/app/mysql ","link":"https://hkxtor.github.io/1VMe2UNvc/"},{"title":"12c可插拔数据库的几种克隆迁移方法","content":"Oacle 多租户环境包含一个容器数据库(CDB)和零个或多个可插拔数据库(PDB)，这种让数据库系统扩展也变得非常的灵活，oracle 12c提供了许多种关于多租户模式下数据库的克隆迁移方式，以下对于几种克隆迁移的方式进行实验介绍。 一．通过现有PDB直接创建（CREATE PLUGGABLE DATABASE..FROM..） 从本地PDB创建 克隆完整PDB 创建语句： CREATE PLUGGABLE DATABASE pdb3 FROM pdb2 PATH_PREFIX = ' /u01/app/oracle/oradata/ ' --- 指定pdb相关联的目录，可以不设置 FILE_NAME_CON VERT = (' /u01/app/oracle/oradata/orclcwd/pdb2/', '/u01/app/oracle/oradata/orclcwd/pdb3/' ) - - 数据文件存放路径，在ASM中可以指定DG SERVICE_NAME_CONVERT = ('pdb2','pdb3') – 服务名转换 NOLOGGING; CREATE PLUGGABLE DATABASE pdb3 FROM pdb2 PATH_PREFIX = '/u01/app/oracle/oradata/' FILE_NAME_CONVERT = ('/u01/app/oracle/product/12.1.0/dbhome_1/dbs/u01/app/oracle/oradata/orclcwd/', '/u01/app/oracle/oradata/orclcwd/pdb3/') SERVICE_NAME_CONVERT = ('pdb2','pdb3'); 主要的选项说明： PATH_PREFIX：将PDB的相对目录对象路径设置为特定目录。因此，需要设置PATH_PREFIX FILE_NAME_CONVERT：指定数据文件的转换路径 Storage: 如果需要限制新建pdb的大小，可以使用storage=xxG 来限制。 创建的过程日志： CREATE PLUGGABLE DATABASE pdb3 FROM pdb2 PATH_PREFIX = '/u01/app/oracle/oradata/' FILE_NAME_CONVERT = ('/u01/app/oracle/product/12.1.0/dbhome_1/dbs/u01/app/oracle/oradata/orclcwd/', '/u01/app/oracle/oradata/orclcwd/pdb3/') SERVICE_NAME_CONVERT = ('pdb2','pdb3') &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 创建命令开始 Fri Aug 18 14:22:11 2017 Opatch XML is skipped for PDB PDB2 (conid=3) &lt;&lt;&lt;&lt;&lt; 跳过PDB2（源）Opatch XML，看起来与版本检查有关 APEX_040200.WWV_FLOW_ADVISOR_CHECKS (CHECK_STATEMENT) - CLOB populated Fri Aug 18 14:24:15 2017 &lt;&lt;&lt;&lt; 开始创建新的PDB3，但此时的状态先为UNUSABLE **************************************************************** Pluggable Database PDB3 with pdb id - 4 is created as UNUSABLE. If any errors are encountered before the pdb is marked as NEW, then the pdb must be dropped **************************************************************** Database Characterset for PDB3 is ZHS16GBK &lt;&lt;&lt; 字符集检查 Fri Aug 18 14:24:26 2017 &lt;&lt;&lt;&lt;&lt;&lt;&lt;&lt; 删除换旧的数据文件并生成新的数据文件 Deleting old file#8 from file$ Deleting old file#9 from file$ Adding new file#11 to file$(old file#8) Adding new file#12 to file$(old file#9) Successfully created internal service pdb3 at open &lt;&lt;&lt;&lt;&lt;&lt; 创建服务成功 ALTER SYSTEM: Flushing buffer cache inst=0 container=4 local &lt;&lt;&lt;&lt;&lt; 刷新新PDB的buffer **************************************************************** Post plug operations are now complete. &lt;&lt;&lt;&lt;&lt; 插入PDB操作 Pluggable database PDB3 with pdb id - 4 is now marked as NEW. &lt;&lt;&lt;&lt;PDB 状态定位NEW **************************************************************** Completed: CREATE PLUGGABLE DATABASE pdb3 FROM pdb2 &lt;&lt;&lt;&lt; 完成 PATH_PREFIX = '/u01/app/oracle/oradata/' FILE_NAME_CONVERT = ('/u01/app/oracle/product/12.1.0/dbhome_1/dbs/u01/app/oracle/oradata/orclcwd/', '/u01/app/oracle/oradata/orclcwd/pdb3/') SERVICE_NAME_CONVERT = ('pdb2','pdb3') 仅克隆PDB元数据 有时并不需要克隆表里的数据，可使用NO DATA来克隆一个PDB，但仅仅克隆元数据。 以下示例： 源PDB中表存在多行数据，这里特意选择了三种情况，看看是否NO DATA的机制如何： SYS 用户的表，表空间在SYSTEM 个人用户的表，表空间在SYSTEM 个人用户的表，表空间在普通表空间 将源PDB打开到read only模式下： ALTER PLUGGABLE DATABASE pdb1 OPEN READ ONLY; 克隆PDB： CREATE PLUGGABLE DATABASE pdb4 FROM pdb3 NO DATA FILE_NAME_CONVERT = ('/u01/app/oracle/oradata/orclcwd/pdb3/', '/u01/app/oracle/oradata/orclcwd/pdb4/'); SQL&gt; CREATE PLUGGABLE DATABASE pdb4 FROM pdb3 NO DATA; CREATE PLUGGABLE DATABASE pdb4 FROM pdb3 NO DATA * ERROR at line 1: ORA-65016: FILE_NAME_CONVERT must be specified SQL&gt; CREATE PLUGGABLE DATABASE pdb4 FROM pdb3 NO DATA 2 FILE_NAME_CONVERT = ('/u01/app/oracle/oradata/orclcwd/pdb3/','/u01/app/oracle/oradata/orclcwd/pdb4/'); Pluggable database created. 打开新克隆的PDB： ALTER PLUGGABLE DATABASE pdb4 OPEN; 到新的PDB下查询表数据： 从查询结果来看，使用NO DATA的方式克隆PDB时，SYSTEM表空间下的表数据是会克隆过去，但用户表空间下表数据库就仅克隆了元数据。 从远程PDB或non-CDB创建 通过远程方式创建克隆主要依靠的是dblink，因此需要源库和目标库之间网络保持畅通，而远处创建的方式和本地创建相差不大，远程模式可以增加从一个NON-CDB数据库克隆到CDB中。 从PDB创建 查看目标CDB当前情况： 在目标CDB创建连接远程CDB的dblink： SQL&gt; create public database link cdb1 connect to system identified by &quot;111111&quot; using 'cdb1'; Database link created. 使用dblink远程创建 SQL&gt; CREATE PLUGGABLE DATABASE pdb5 FROM pdb4@cdb1 2 FILE_NAME_CONVERT = ('/u01/app/oracle/oradata/orclcwd/pdb4/','/u01/app/oracle/oradata/orclcwd/pdb5/'); Pluggable database created. 完成创建： 从NOCDB创建 在目标CDB创建连接远程非CDB的dblink： SQL&gt; create public database link nocdb1 connect to system identified by &quot;111111&quot; using 'nocdb1'; Database link created. 使用dblink远程创建 SQL&gt; CREATE PLUGGABLE DATABASE pdb6 FROM nocdb1@nocdb1 2 FILE_NAME_CONVERT = ('/u01/app/oracle/oradata/nocdb1/','/u01/app/oracle/oradata/orclcwd/pdb6/'); Pluggable database created. 创建完成 执行PDB转换脚本 SQL&gt; alter session set container=pdb6; SQL&gt; @?/rdbms/admin/ noncdb_to_pdb.sql Plug 过程的一些问题： 通过PDB_PLUG_IN_VIOLATIONS视图可以查询plug过程中的问题，例如以下，源PDB和当前CDB的字符集不同导致PDB open 后是限制模式，这个可以通过 ALTER DATABASE CHARACTER SET internal_use ZHS16GBK; 更改，如果在 实际应 用中就要事先注意 检查 字符集是否相同。 二.通过插拔方式创建（CREATE PLUGGABLE DATABASE..USING ‘XML’..） 插拔的方式，是将一个PDB从CDB中拔出，之后插入到另外一个CDB的过程，一个拔掉的 PDB 由描述 PDB 的 XML 文件和其相关数据文件 组 成。 从PDB插拔 选择准备拔出的 PDB ，这里选择 PDB4. 关闭 PDB 生成PDB的描述XML文件 ALTER PLUGGABLE DATABASE PDB4 UNPLUG INTO '/home/oracle/PDB4.xml'; 将PDB4的文件传输到目标库相同路径下： 将生成的XML文件传输到目标库 执行DBMS_PDB.CHECK_PLUG_COMPATIBILITY 检查要插入PDB是否和目标CDB兼容。 SET SERVEROUTPUT ON DECLARE compatible CONSTANT VARCHAR2(3) := CASE DBMS_PDB.CHECK_PLUG_COMPATIBILITY( pdb_descr_file =&gt; '/home/oracle/PDB4.xml') WHEN TRUE THEN 'YES' ELSE 'NO' END; BEGIN DBMS_OUTPUT.PUT_LINE(compatible); END; / SQL&gt; SET SERVEROUTPUT ON SQL&gt; DECLARE 2 compatible CONSTANT VARCHAR2(3) := 3 CASE DBMS_PDB.CHECK_PLUG_COMPATIBILITY( 4 pdb_descr_file =&gt; '/home/oracle/PDB4.xml') 5 WHEN TRUE THEN 'YES' 6 ELSE 'NO' 7 END; 8 BEGIN 9 DBMS_OUTPUT.PUT_LINE(compatible); 10 END; 11 / NO &lt;&lt;&lt;&lt; 检查不通过 ，原来出现字符集不同 SQL&gt; ALTER SYSTEM ENABLE RESTRICTED SESSION; System altered. SQL&gt; ALTER DATABASE CHARACTER SET internal_use ZHS16GBK; Database altered. SQL&gt; SET SERVEROUTPUT ON SQL&gt; DECLARE 2 compatible CONSTANT VARCHAR2(3) := 3 CASE DBMS_PDB.CHECK_PLUG_COMPATIBILITY( 4 pdb_descr_file =&gt; '/home/oracle/PDB4.xml') 5 WHEN TRUE THEN 'YES' 6 ELSE 'NO' 7 END; 8 BEGIN 9 DBMS_OUTPUT.PUT_LINE(compatible); 10 END; 11 / YES &lt;&lt;&lt;&lt; 检查 通 过 PL/SQL procedure successfully completed. 对于插入一个PDB，必须满足以下条件： 目标CDB必须与源CDB具有相同的字节码（主要涉及平台问题） 。 CDB必须安装相同的选项 。 源CDB和目标CDB必须具有兼容的字符集和国家字符集。 使用XML元数据文件把PDB插入（克隆模式） create pluggable database MYPDB3 AS CLONE using '/home/oracle/PDB4.xml' NOCOPY TEMPFILE REUSE; 这里使用NOCOPY是因为将目标库数据文件路径设成了与源库相同。 打开新的插入的PDB,但出现错误 SQL&gt; !oerr ora 65054 65054, 00000, &quot;Cannot open a pluggable database in the desired mode.&quot; // *Cause: An attempt was made to open a pluggable database in a mode // incompatible with that of the CDB. // *Action: Open the CDB in a compatible mode first and retry the operation. 看起来是新的PDB和CDB OPEN时不兼容，这里我尝试重启整个CDB后竟然可以顺利打开新插入的PDB了。 从 NON-CDB 插拔 从NON-CDB转换克隆的模式实际与从CDB相差不大，与从现有NOCDB创建的模式一样，这里也需要执行noncdb_to_pdb.sql脚本来转换数据字典等。 以下列举出执行的语句： 关闭原NONCDB数据库,并开启到只读模式 sqlplus / as sysdba sql&gt; shutdown immediate sql&gt; startup open read only 生成数据库的XML元数据文件。 BEGIN DBMS_PDB.DESCRIBE(pdb_descr_file =&gt; '/home/oracle/12cNonPDB.xml'); END; / 关闭数据库 sql&gt; shutdown immediate 同样将原数据库文件传输到新数据库磁盘中。 检查兼容性 SET SERVEROUTPUT ON; DECLARE compatible CONSTANT VARCHAR2(3) := CASE DBMS_PDB.CHECK_PLUG_COMPATIBILITY(pdb_descr_file =&gt; '/home/oracle/12cNonPDB.xml') WHEN TRUE THEN 'YES' ELSE 'NO' END; BEGIN DBMS_OUTPUT.PUT_LINE(compatible); END; / 检查是否有错误 col cause for a20 col name for a20 col message for a35 word_wrapped select name,cause,type,message,status from PDB_PLUG_IN_VIOLATIONS where name='&lt;noncdb database name&gt;'; 创建PDB CREATE PLUGGABLE DATABASE PDB8 USING ' /home/oracle/12cNonPDB.xml' COPY FILE_NAME_CONVERT = ('/u01/app/oracle/12c/oradata/12cNonPDB/','/u01/app/oracle/oradata/12c/PDB8/'); 执行转换脚本 sql&gt; ALTER SESSION SET CONTAINER= PDB8; sql&gt; @$ORACLE_HOME/rdbms/admin/noncdb_to_pdb.sql 打开新的PDB ALTER PLUGGABLE DATABASE PDB8 OPEN; 三．通过RMAN备份恢复 整体数据库备份恢复 有时可能需要迁移的仅仅是其中某几个PDB，在整库数据量不大情况下，可以直接备份整库来异机恢复即可，这样和普通的的数据库模式是相同的。 整库备份 run{ allocate channel CH1 device type disk format '/home/oracle/backup/full_db_%U'; backup database include current controlfile plus archivelog ; release channel CH1 ; } BACKUP current controlfile format '/home/oracle/backup/control_%d_%T_%u.ctl'; 传输备份片到目标库 [oracle@redhat1 ~]$ pwd /home/oracle [oracle@redhat1 ~]$ scp -r backup 172.16.155.67:/home/oracle/ 恢复控制文件 Startup nomout restore controlfile from '/home/oracle/backup/control_ORCLCWD_20170819_1esc91u4.ctl'; alter database mount; 恢复全库 run{ allocate channel CH1; restore database ; recover database; release channel CH1 ; } alter database open resetlogs; 只恢复CDB、pdb$seed和需要的PDB 备份数据库 这里使用上一步骤的全库备份，这里有个问题，就是我只需要恢复其中某一个PDB，那么，是否可以直接备份root database ,种子pdb 和所要的pdb来单独恢复，这个在后面进行详细实验。 创建参数文件. 这个不做说明 恢复控制文件 startup nomout restore controlfile from '/home/oracle/backup/control_ORCLCWD_20170819_1esc91u4.ctl'; alter database mount; 恢复所需要的 CDB$ROOT,PDB$SEED和PDB4 run{ ALLOCATE CHANNEL c1 TYPE disk; restore database root ; -------------------------&gt;CDB$ROOT restore database &quot;PDB$SEED&quot;; --------&gt;PDB$SEED is required restore database PDB4; --------------&gt;PDB we want to restore RELEASE CHANNEL c1; } 如果源库和目标库的数据文件路径不同，这使用set new name方式来更改文件路径。 跳过不需要的PDB的表空间来做recover. 在本示例中， 数据库中除了CDB$ROOT和PDB$SEED，还有PDB2和PDB4，选择恢复的是PDB4，因此PDB2在recover时必须进行排除。 run{ recover database skip forever tablespace PDB2:SYSTEM,PDB2:SYSAUX; } 打开数据库 打开后查看发现有pdb2，这个实际时不可用的，且没有实际数据，直接drop掉即可。 SQL&gt; show pdbs CON_ID CON_NAME OPEN MODE RESTRICTED ---------- ------------------------------ ---------- ---------- 2 PDB$SEED MOUNTED 3 PDB2 MOUNTED 5 PDB4 MOUNTED SQL&gt; alter pluggable database PDB2 open; alter pluggable database PDB2 open * ERROR at line 1: ORA-01147: SYSTEM tablespace file 8 is offline SQL&gt; drop pluggable database pdb2 including datafiles; Pluggable database dropped. 而在打开PDB4时报出了ORA-65086，这里可以试下插拔一次。 SQL&gt; alter pluggable database pdb4 open; alter pluggable database pdb4 open * ERROR at line 1: ORA-65086: cannot open/close the pluggable database SQL&gt; alter pluggable database pdb4 unplug into '/tmp/pdb41.xml'; Pluggable database altered. 1* select pdb_name,status from dba_pdbs SQL&gt; / PDB_NAME STATUS -------------------- --------- PDB$SEED NEW PDB4 UNPLUGGED SQL&gt; drop pluggable database pdb4 keep datafiles; Pluggable database dropped. SQL&gt; select pdb_name,status from dba_pdbs; PDB_NAME STATUS -------------------- --------- PDB$SEED NEW SQL&gt; create pluggable database PDB4 using '/tmp/pdb41.xml' nocopy tempfile reuse; Pluggable database created. SQL&gt; select pdb_name,status from dba_pdbs; PDB_NAME STATUS -------------------- --------- PDB4 NEW PDB$SEED NEW SQL&gt; alter pluggable database pdb4 open; Pluggable database altered. SQL&gt; show pdbs CON_ID CON_NAME OPEN MODE RESTRICTED ---------- ------------------------------ ---------- ---------- 2 PDB$SEED MOUNTED 3 PDB4 READ WRITE NO 经过测试，可以只对需要的PDB进行备份后进行恢复即可,在迁移时并不需要整个库都备份，这样的话可以节省不少时间和空间。 run{ allocate channel CH1 device type disk format '/home/oracle/backup/full_db_%U'; backup database root include current controlfile plus archivelog; backup database &quot;PDB$SEED&quot;; backup pluggable database PDB4 include current controlfile plus archivelog; release channel CH1 ; } BACKUP current controlfile format '/home/oracle/backup/control_%d_%T_%u.ctl'; 后面恢复的方法与以上相同。 ","link":"https://hkxtor.github.io/qulIB3Rk0/"},{"title":"如何判断数据库IO是否慢","content":"1. 引言 一个项目的数据库响应慢的问题，结论就是操作系统层面上的IO性能差的问题，怎么样才能更有说服力。 我们一般衡量IO性能主要用两种指标来衡量。 响应时间：用微秒来测量完成一项操作所需的时间，这个一般由oracle来采集统计。 吞吐量：以每个单位时间内完成的操作数量来测量。这个一般通过操作系统下的工具来统计，例如iostat。 本文主要是阐述如何从oracle的角度来确定IO是否慢，不再详细说明吞吐量及其测量方法。 2. 怎么才算IO“慢” IO慢是一个很主观的术语，它更多的取决于用户对系统和硬件的预期和实际的差异，这个差异是一个比较主观的感觉，量化到具体性能指标来看，在企业级平台下，当IO请求的响应时间大于10ms时，用户会开始敏感。不过响应时间是会不断变化的，有可能是数据从文件系统迁移到共享存储上，也可能是存储设备出现异常，又或者是业务增长导致的IO性能达到峰值。这就需要通过对响应时间这个指标作出作出多维度的测量。 3. 响应时间 硬件不必对于每个IO请求都有相同的反映。总会有可能出现高峰和低谷。因此使用平均值是一种测量响应时间的通用方法。 注意：为了减缓这种高峰/低谷的异常场景带来的问题，样例数据量需要比较大。样例数据量应该至少是每小时1000次操作，目的就是为了提供给决测更可信和实用的依据。 IO的类型 平均响应时间直接关联到具体的IO类型： 读或写 单块或多块单块IO，指一次只读一个块。例如，当一个session等待一个单块IO时，典型的等待事件就是“db file sequential read”，表明正在等待需要的块。 多块读指的是一次读多个块，从2到128个Oracle块不等，依赖于块的大小与操作系统设置。通常一个多块请求容量上有1MB的限制。例如当一个session等待一次多块IO时，典型的等待事件就是“db file scattered read”，表明正在等待需要的块。 同步或异步同步(阻塞)操作等待硬件完成物理IO，完成后能得到通知，合理地管理操作的成功或失败(成功读的情况下可以接收结果)。当需要等待系统调用结果的时候，进程的执行是被堵塞的。 对于异步(非阻塞)操作，一旦IO请求传递到硬件，或放入操作系统的队列中(典型的情况是物理IO开始之前)，系统调用会立即返回。进程的执行不会被堵塞，因为它不需要等待系统调用的结果。它能继续执行，当IO操作有结果时再接收。 响应时间的阈值 一次典型的多块同步读64x 8k(总计512KB)的平均时间应该在未出现IO变慢的情况下大约是20毫秒左右。小请求应该更快(10-20毫秒)，大请求的消耗时间应该不多于25毫秒。异步操作应该至少和同步操作一样快，甚至还要更快。单块读至少应该和多块读一样快，甚至还要更快。“log file parallel write”，“control file write”和“direct path writes“等待时间应该不多于15毫秒。数据文件写的测量不像读那样简单。DBWR以批量的方式(&quot;db file parallel write&quot;)异步写入块，现在还没有写操作响应时间的标准。如果DBWR(多块或单块，带或不带IO salves)足够快速能够清理脏块，那么其他的等待事件和统计信息就会显露出来。作为规则，超过上述等待事件时间的等待事件都应该详细分析，当对比之前的时间消耗，有明显变化时更需要知晓。 注意：当系统低于这些最大阈值的时候，并不意味着没有其他的调优方法。 响应时间因系统而有所不同。例如，接下来的几项内容可以看做是正常平均值： 多块同步读时间是10毫秒。 单块同步读时间是5毫秒。 'log file parallel write'时间是3毫秒。 以上是基于多块IO比单块IO需要更多的IO子系统资源的前提。如果接受这些建议，redo日志最好放在最快的磁盘，并且没有其它并发活动的争用。 以下是各IO相关等待事件的响应时间阈值： Wait Event R/W Synchronous/ Asynchronous Singleblock/ Multiblock Elapsed Time control file parallel write Write Asynchronous Multi &lt; 15ms control file sequential read Read Synchronous Single &lt; 20 ms db file parallel read Read Asynchronous Multi &lt; 20 ms db file scattered read Read Synchronous Multi &lt; 20 ms db file sequential read Read Synchronous Single &lt; 20 ms direct path read Read Asynchronous Multi &lt; 20 ms direct path read temp Read Asynchronous Multi &lt; 20 ms direct path write Write Asynchronous Multi &lt; 15 ms direct path write temp Write Asynchronous Multi &lt; 15 ms log file parallel write Write Asynchronous Multi &lt; 15 ms 确定响应时间的途径 10046 trace file 当在10046 trace中使用level 8或12时，会包含相关的等待事件的信息，响应时间是ela字段，单位是微秒。 WAIT #5: nam='cell single block physical read' ela= 672 cellhash#=2520626383 diskhash#=1377492511 bytes=16384 obj#=63 tim=1280416903276618 &gt;&gt; 672 microseconds = 0.672 ms WAIT #5: nam='db file sequential read' ela= 1018 file#=2 block#=558091 blocks=1 obj#=0 tim=10191852599110 &gt;&gt; 1018 microseconds =&gt; 1.018 ms System State Dump 对于每个系统级的进程，等待信息包括在进程信息中。通常显示一个活动的waiting for，或者等待完成，进程正在CPU中执行waited for/last wait for。 其中waiting for表示进程处于等待状态。11g之前可以查看seconds since wait started字段，显示进程已经等待多久了。从11gR1开始，”total“字段显示等待的时间。 如果waiting for显示一个进程正在等待一个IO相关的操作，seconds since wait started&gt;0，表示可能IO丢失，session处于hang状态。(因为之前提到过平均可接受时间是20毫秒，任何IO等待时间超过1秒都需要关注)。 last wait for是与11g之前的版本相关的，表明进程不在等待(例如正在使用CPU)。等待时间记录到”wait_time“字段。(11g中wait_time被not in wait替代) last wait for 'db file sequential read' blocking sess=0x0 seq=100 wait_time=2264 seconds since wait started=0 file#=45, block#=17a57, blocks=1 &gt;&gt; 2264 microseconds =&gt; 2.264 ms waited for表示session不在等待。通常是11gR1以后的系统级trace中使用。total字段表示等待的总时间。 0: waited for 'db file sequential read' file#=9, block#=46526, blocks=1 wait_id=179 seq_num=180 snap_id=1 wait times: snap=0.007039 sec, exc=0.007039 sec, total=0.007039 sec wait times: max=infinite wait counts: calls=0 os=0 &gt;&gt; 0.007039 sec =&gt; 7.039 ms Statspack 与AWR reports 前台进程和后台进程的等待事件，平均响应时间通过Wait Avg(ms)反映(以毫秒计算的平均读)。 表空间IO 平均响应时间通过Av Rd (ms)反映(以毫秒计算的平均读)。 等待事件直方图可以提供组成这些平均值的写操作时间分布。他会展示出所有写操作都接近于平均值，还是会有若干波峰或波谷的情况。每列都表明每个bucket之间等待事件时间分布的百分比。例如，&lt;16ms的等待大于&lt;8ms。只要最大的百分比是从&lt;1ms到16ms的范围内，那么IO性能通常就可以接受。 4. 总结 本文的目标不是为了排查IO变慢的原因，而是为了如何寻找判定IO慢的证据。如果性能变差，那么IO慢可能成为性能问题的一个潜在原因，需要从数据库角度来分析如何采集支持的证据；如果潜在原因是由于操作系统级别的IO慢，那么负责IO子系统工程师需要参与进来诊断和修复这个问题。 ","link":"https://hkxtor.github.io/vQKm4MfiK/"}]}